===== AllCode.txt =====


===== Cargo.toml =====
[package]
name    = "tsqc"
version = "0.1.0"
edition = "2024"
license = "MIT OR Apache-2.0"

[lib]
# Build both a Rust static lib (for tests & other crates) *and* a cdylib for PyO3.
crate-type = ["rlib", "cdylib"]

[dependencies]
pyo3        = { version = "0.25.1", features = ["extension-module"] }
bitvec      = "1.0"
rand        = "0.8"
rand_chacha = "0.3"

[dev-dependencies]
approx = "0.5"

[package.metadata.maturin]
python-packages = ["tsqc"]          # neem het hele tsqc-package op



===== pyproject.toml =====
[build-system]
requires = ["maturin>=1.0,<2.0"]
build-backend = "maturin"

[project]
name = "tsqc"
version = "0.1.0"
description = "Tabu Search for Quasi-Cliques (Rust core, Python bindings)"
requires-python = ">=3.9"
authors = [{ name = "Your Name", email = "you@example.com" }]
license = { text = "MIT OR Apache-2.0" }
readme = "README.md"

[tool.maturin]
#  The compiled extension will be installed as tsqc/_native.* (pyd/so)
module-name     = "tsqc._native"
#  Include the entire pure-Python package in the wheel
python-packages = ["tsqc"]
#  Build in release mode by default when 'maturin develop -r' is used

===== quick_check.py =====
from pathlib import Path
from tsqc.data_loader import load_dimacs

n, edges = load_dimacs(Path("benchmarks/hamming8-4.clq"))
print(f"n={n}, |E|={len(edges)}")

===== README.md =====
# TSQC – Tabu Search for Quasi-Cliques in Rust

===== src\construct.rs =====
//! Constructors for an initial vertex subset S₀.
//!
//! * `random_k` – choose k distinct vertices uniformly at random.
//! * `greedy_k` – take the k highest-degree vertices.
//!
//! Both return a ready-to-use [`Solution`] with edge counts pre-computed.

use crate::{graph::Graph, solution::Solution};
use rand::seq::SliceRandom;
use rand::Rng;

/// Pick `k` distinct vertices uniformly-at-random.
///
/// `rng` is any mutable RNG; `k` must not exceed `graph.n()`.
pub fn random_k<'g, R>(graph: &'g Graph, k: usize, rng: &mut R) -> Solution<'g>
where
    R: Rng + ?Sized,
{
    assert!(k <= graph.n(), "k larger than graph size");
    let mut idx: Vec<usize> = (0..graph.n()).collect();
    idx.shuffle(rng);

    let mut sol = Solution::new(graph);
    for &v in &idx[..k] {
        sol.add(v);
    }
    sol
}

/// Greedy initialisation: take the `k` highest-degree vertices.
pub fn greedy_k<'g>(graph: &'g Graph, k: usize) -> Solution<'g> {
    assert!(k <= graph.n(), "k larger than graph size");
    let mut idx: Vec<usize> = (0..graph.n()).collect();
    idx.sort_unstable_by_key(|&v| std::cmp::Reverse(graph.degree(v)));

    let mut sol = Solution::new(graph);
    for &v in &idx[..k] {
        sol.add(v);
    }
    sol
}

/*──────────── tests ────────────*/
#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Cursor;
    use rand_chacha::ChaCha8Rng;
    use rand::SeedableRng;

    fn triangle() -> Graph {
        let dimacs = b"p edge 3 3\ne 1 2\ne 1 3\ne 2 3\n";
        Graph::parse_dimacs(Cursor::new(dimacs)).unwrap()
    }

    #[test]
    fn random_vs_greedy() {
        let g = triangle();

        let mut rng = ChaCha8Rng::seed_from_u64(42);
        let r = random_k(&g, 2, &mut rng);
        assert_eq!(r.size(), 2);

        let g2 = greedy_k(&g, 2);
        assert_eq!(g2.size(), 2);
    }
}

===== src\diversify.rs =====
//! Diversification operators for TSQC.

use crate::{solution::Solution, tabu::DualTabu};
use rand::seq::SliceRandom;
use rand::Rng;

/// Heavy perturbation: remove ⌈γ·|S|⌉ random vertices, then greedily add
/// the same number of highest-degree outsiders. Resets tabu.
pub fn heavy_perturbation<'g, R>(
    sol: &mut Solution<'g>,
    tabu: &mut DualTabu,
    rng: &mut R,
    gamma: f64,
) where
    R: Rng + ?Sized,
{
    let k = sol.size();
    if k == 0 { return; }
    let remove_cnt = ((gamma.clamp(0.1, 0.9) * k as f64).ceil() as usize).min(k);

    /* randomly pick vertices to remove */
    let mut inside: Vec<usize> = sol.bitset().iter_ones().collect();
    inside.shuffle(rng);
    for &v in &inside[..remove_cnt] {
        sol.remove(v);
    }

    /* add highest-degree outsiders (could include previously removed ones) */
    let mut outsiders: Vec<usize> =
        (0..sol.graph().n()).filter(|&v| !sol.bitset()[v]).collect();
    outsiders.sort_unstable_by_key(|&v| std::cmp::Reverse(sol.graph().degree(v)));
    for &v in outsiders.iter().take(remove_cnt) {
        sol.add(v);
    }

    tabu.reset();
}

/// Mild perturbation: drop worst critical vertex, add best outsider.
pub fn mild_perturbation<'g>(sol: &mut Solution<'g>, tabu: &mut DualTabu) {
    let curr_d   = sol.density();
    let crit_thr = (curr_d * (sol.size() as f64 - 1.0)).floor() as usize;

    /* worst critical vertex = lowest internal degree < threshold */
    let mut worst: Option<(usize /*deg*/, usize /*v*/)> = None;
    for v in sol.bitset().iter_ones() {
        let deg_in = sol.graph().neigh_row(v)
            .iter_ones()
            .filter(|&j| sol.bitset()[j])
            .count();
        if deg_in < crit_thr && worst.map_or(true, |(d, _)| deg_in < d) {
            worst = Some((deg_in, v));
        }
    }
    let (_, u) = match worst { Some(p) => p, None => return };

    sol.remove(u);                    // end immutable borrows

    /* best outsider by #edges into current S */
    let mut best: Option<(usize, usize)> = None;
    for w in 0..sol.graph().n() {
        if sol.bitset()[w] { continue; }
        let edges = sol.graph().neigh_row(w)
            .iter_ones()
            .filter(|&j| sol.bitset()[j])
            .count();
        if best.map_or(true, |(e, _)| edges > e) {
            best = Some((edges, w));
        }
    }
    if let Some((_, w)) = best { sol.add(w); }

    tabu.reset();
}

/*────────────────── tests ──────────────────*/
#[cfg(test)]
mod tests {
    use super::*;
    use crate::{construct::greedy_k, graph::Graph, tabu::DualTabu};
    use rand_chacha::ChaCha8Rng;
    use rand::SeedableRng;
    use std::io::Cursor;

    fn square() -> Graph {
        let dimacs = b"p edge 4 4\ne 1 2\ne 2 3\ne 3 4\ne 4 1\n";
        Graph::parse_dimacs(Cursor::new(dimacs)).unwrap()
    }

    #[test]
    fn heavy_keeps_size() {
        let g = square();
        let mut sol  = greedy_k(&g, 3);
        let mut tabu = DualTabu::new(g.n(), 2, 2);
        let before_k = sol.size();

        let mut rng = ChaCha8Rng::seed_from_u64(7);
        heavy_perturbation(&mut sol, &mut tabu, &mut rng, 0.5);

        // Heavy perturbation must keep |S| constant.
        assert_eq!(sol.size(), before_k);
    }

    #[test]
    fn mild_keeps_size() {
        let g = square();
        let mut sol  = greedy_k(&g, 3);
        let mut tabu = DualTabu::new(g.n(), 2, 2);
        let before_k = sol.size();

        mild_perturbation(&mut sol, &mut tabu);

        assert_eq!(sol.size(), before_k);
    }
}

===== src\graph.rs =====
//! Simple undirected graph stored as an adjacency BitVec per row.
//! Supports DIMACS *.clq parsing and edge iteration.

use bitvec::prelude::*;
use std::io::{BufRead, Read};

#[derive(Clone, Debug)]
pub struct Graph {
    /// Row‐major adjacency; `adj[i][j]` is 1 ⇔ edge (i,j) exists, j≠i.
    adj: Vec<BitVec>,
}

impl Graph {
    /*────────── constructors ──────────*/

    /// Empty graph with `n` isolated vertices.
    pub fn with_vertices(n: usize) -> Self {
        let mut rows = Vec::with_capacity(n);
        for _ in 0..n {
            rows.push(bitvec![0; n]);
        }
        Self { adj: rows }
    }

    /// Build from explicit edge list (0-based indices, undirected).
    pub fn from_edge_list(n: usize, edges: &[(usize, usize)]) -> Self {
        let mut g = Self::with_vertices(n);
        for &(u, v) in edges {
            g.add_edge(u, v);
        }
        g
    }

    /// Parse DIMACS *.clq format from any buffered reader.
    pub fn parse_dimacs<R: Read>(reader: R) -> std::io::Result<Self> {
        let mut n = 0usize;
        let mut edges: Vec<(usize, usize)> = Vec::new();

        for line in std::io::BufReader::new(reader).lines() {
            let line = line?;
            let line = line.trim();
            if line.is_empty() || line.starts_with('c') { continue; }
            if line.starts_with('p') {
                // p edge <n> <m>
                let parts: Vec<_> = line.split_whitespace().collect();
                if parts.len() >= 3 {
                    n = parts[2].parse().unwrap_or(0);
                }
            } else if line.starts_with('e') {
                // e u v   (1-based)
                let parts: Vec<_> = line.split_whitespace().collect();
                if parts.len() >= 3 {
                    let u: usize = parts[1].parse().unwrap();
                    let v: usize = parts[2].parse().unwrap();
                    edges.push((u - 1, v - 1));
                }
            }
        }
        Ok(Self::from_edge_list(n, &edges))
    }

    /*────────── getters ──────────*/

    #[inline] pub fn n(&self) -> usize { self.adj.len() }

    /// Number of edges (each counted once).
    pub fn m(&self) -> usize {
        let mut m = 0usize;
        for i in 0..self.n() {
            for j in self.neigh_row(i).iter_ones().filter(|&j| j > i) {
                if self.adj[i][j] { m += 1; }
            }
        }
        m
    }

    /// Degree of vertex v.
    #[inline]
    pub fn degree(&self, v: usize) -> usize {
        self.adj[v].count_ones()
    }

    /// Immutable row slice for adjacency of v.
    #[inline]
    pub fn neigh_row(&self, v: usize) -> &BitSlice {
        &self.adj[v]
    }

    /// Return all edges as Vec<(u,v)> with u < v.
    pub fn edge_list(&self) -> Vec<(usize, usize)> {
        let mut edges = Vec::with_capacity(self.m());
        for i in 0..self.n() {
            for j in self.neigh_row(i).iter_ones().filter(|&j| j > i) {
                edges.push((i, j));
            }
        }
        edges
    }

    /*────────── mutators ──────────*/

    #[inline]
    pub fn add_edge(&mut self, u: usize, v: usize) {
        assert!(u < self.n() && v < self.n() && u != v);
        self.adj[u].set(v, true);
        self.adj[v].set(u, true);
    }
}

/*────────────────── tiny unit check ──────────────────*/
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn tiny_triangle() {
        let g = Graph::from_edge_list(3, &[(0, 1), (0, 2), (1, 2)]);
        assert_eq!(g.n(), 3);
        assert_eq!(g.m(), 3);
        assert_eq!(g.edge_list().len(), 3);
    }
}

===== src\lib.rs =====
//! tsqc – Rust implementation of the TSQC algorithm with optional Python bindings.

use pyo3::prelude::*;
use pyo3::wrap_pyfunction;

pub mod graph;
pub mod solution;
pub mod tabu;
pub mod construct;
pub mod neighbour;
pub mod diversify;
pub mod params;
pub mod restart;
pub mod maxk;

pub use graph::Graph;
pub use solution::Solution;
pub use params::Params;
pub use restart::solve_fixed_k;
pub use maxk::solve_maxk;

/* helper re-exports for advanced Rust callers */
pub use construct::{random_k, greedy_k};
pub use neighbour::{improve_once, improve_until_local_optimum};
pub use diversify::{heavy_perturbation, mild_perturbation};

use rand_chacha::ChaCha8Rng;
use rand::SeedableRng;
use std::fs::File;
use std::io::BufReader;

//////////////////////////////////////////////////////////////
/// --------------- PyO3 wrappers ---------------------------
//////////////////////////////////////////////////////////////

/// Fixed-k solver.  
/// Returns the **density** of the best k-subset found
/// (γ-feasible or not – caller decides how to interpret it).
#[pyfunction]
#[pyo3(signature = (edges, n, k, gamma, seed))]
fn solve_k_py(
    edges: Vec<(usize, usize)>,
    n:     usize,
    k:     usize,
    gamma: f64,
    seed:  u64,
) -> PyResult<f64> {
    let g = Graph::from_edge_list(n, &edges);

    let mut params = Params::default();
    params.gamma_target = gamma;

    let mut rng = ChaCha8Rng::seed_from_u64(seed);
    let sol      = solve_fixed_k(&g, k, &mut rng, &params);

    Ok(sol.density())
}

/// Any-k solver.  
/// Returns **(best_size, density)** of the largest γ-feasible quasi-clique found.
#[pyfunction]
#[pyo3(signature = (edges, n, gamma, seed))]
fn solve_max_py(
    edges: Vec<(usize, usize)>,
    n:     usize,
    gamma: f64,
    seed:  u64,
) -> PyResult<(usize, f64)> {
    let g = Graph::from_edge_list(n, &edges);

    let mut params = Params::default();
    params.gamma_target = gamma;

    let mut rng = ChaCha8Rng::seed_from_u64(seed);
    let sol      = solve_maxk(&g, &mut rng, &params);

    Ok((sol.size(), sol.density()))
}

/// Fast DIMACS *.clq parser exposed to Python.
/// Returns *(n_vertices, edge_list)* with 0-based indices.
#[pyfunction]
fn parse_dimacs_py(path: &str) -> PyResult<(usize, Vec<(usize, usize)>)> {
    let file  = File::open(path)?;
    let graph = Graph::parse_dimacs(BufReader::new(file))?;
    Ok((graph.n(), graph.edge_list()))
}

//////////////////////////////////////////////////////////////
/// --------------- module bootstrap ------------------------
//////////////////////////////////////////////////////////////

/// Compiled as `tsqc/_native.*`
#[pymodule]
fn _native(_py: Python<'_>, m: &Bound<'_, PyModule>) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(solve_k_py,   m)?)?;
    m.add_function(wrap_pyfunction!(solve_max_py, m)?)?;
    m.add_function(wrap_pyfunction!(parse_dimacs_py, m)?)?;
    Ok(())
}

===== src\maxk.rs =====
//! Outer “max-k” search (Algorithm 2).
//!
//! For k = 2 … n it calls `solve_fixed_k`, keeping the **largest γ-feasible
//! set** found so far (ties broken by higher density).  The loop exits early
//! if it encounters a full clique (density ≈ 1).

use crate::{
    params::Params,
    restart::solve_fixed_k,
    solution::Solution,
    Graph,
};
use rand::Rng;

pub fn solve_maxk<'g, R>(
    graph: &'g Graph,
    rng: &mut R,
    p: &Params,
) -> Solution<'g>
where
    R: Rng + ?Sized,
{
    let mut best_sol = Solution::new(graph);  // empty ← not γ-feasible
    let mut best_k   = 0usize;                // track size for clarity

    for k in 2..=graph.n() {
        let sol_k = solve_fixed_k(graph, k, rng, p);

        /* consider only γ-feasible candidates */
        if !sol_k.is_gamma_feasible(p.gamma_target) {
            continue;
        }

        if sol_k.size() > best_k
            || (sol_k.size() == best_k && sol_k.density() > best_sol.density())
        {
            best_k   = sol_k.size();
            best_sol = sol_k;

            /* found a clique ⇒ nothing larger can beat density 1.0 */
            if best_sol.density() >= 1.0 - f64::EPSILON {
                break;
            }
        }
    }

    best_sol
}

===== src\neighbour.rs =====
//! Critical-set add / remove / swap neighbourhood (Algorithm 1)
//!
//! Move order per iteration (best-improving first):
//!   1. ADD       – insert outsider w that maximises Δρ
//!   2. REMOVE    – drop a “critical” vertex u (deg(u) < ⌊ρ(|S|-1)⌋)
//!   3. SWAP      – replace critical u with outsider w
//!
//! The first move that improves either the current density or the global
//! best (aspiration) is executed.  Dual-tabu lists prevent immediate
//! reversal unless the aspiration criterion fires.

use crate::{solution::Solution, tabu::DualTabu};

/// Apply **one** intensification step; returns `true` if `sol` improved.
pub fn improve_once<'g>(
    sol: &mut Solution<'g>,
    tabu: &mut DualTabu,
    global_best_density: f64,
) -> bool {
    tabu.update_tenures(sol.size());          // adaptive tenures

    let g  = sol.graph();
    let k  = sol.size();
    let m  = sol.edges();
    let d  = sol.density();

    /* helpers --------------------------------------------------------- */
    let dens_after = |m_new: usize, k_new: usize| -> f64 {
        if k_new < 2 { 0.0 } else { 2.0 * m_new as f64 / (k_new * (k_new - 1)) as f64 }
    };

    let dens_if_add = |w: usize| -> f64 {
        let gain = g.neigh_row(w)
            .iter_ones()
            .filter(|&j| sol.bitset()[j])
            .count();
        dens_after(m + gain, k + 1)
    };

    let dens_if_rem = |u: usize| -> f64 {
        let loss = g.neigh_row(u)
            .iter_ones()
            .filter(|&j| sol.bitset()[j])
            .count();
        dens_after(m - loss, k - 1)
    };

    /* identify critical vertices (internal degree below threshold) ---- */
    let crit_thr = (d * (k as f64 - 1.0)).floor() as usize;
    let critical: Vec<usize> = sol.bitset()
        .iter_ones()
        .filter(|&u| {
            let deg_in = g.neigh_row(u)
                .iter_ones()
                .filter(|&j| sol.bitset()[j])
                .count();
            deg_in < crit_thr
        })
        .collect();

    /* 1 ── ADD -------------------------------------------------------- */
    for w in 0..g.n() {
        if sol.bitset()[w] || tabu.is_tabu_u(w) { continue; }
        let d_new = dens_if_add(w);
        if d_new > d || d_new > global_best_density {
            sol.add(w);
            tabu.forbid_u(w);
            tabu.step();
            return true;
        }
    }

    /* 2 ── REMOVE (critical) ----------------------------------------- */
    for &u in &critical {
        if tabu.is_tabu_v(u) { continue; }
        let d_new = dens_if_rem(u);
        if d_new > d || d_new > global_best_density {
            sol.remove(u);
            tabu.forbid_v(u);
            tabu.step();
            return true;
        }
    }

    /* 3 ── SWAP critical u with outsider w --------------------------- */
    for &u in &critical {
        if tabu.is_tabu_v(u) { continue; }

        let loss_u = g.neigh_row(u)
            .iter_ones()
            .filter(|&j| sol.bitset()[j])
            .count();

        for w in 0..g.n() {
            if sol.bitset()[w] || tabu.is_tabu_u(w) { continue; }

            let gain_w = g.neigh_row(w)
                .iter_ones()
                .filter(|&j| j != u && sol.bitset()[j])
                .count();

            let d_new = dens_after(m - loss_u + gain_w, k);

            if d_new > d || d_new > global_best_density {
                sol.remove(u);
                sol.add(w);
                tabu.forbid_v(u);
                tabu.forbid_u(w);
                tabu.step();
                return true;
            }
        }
    }

    /* no improving move ------------------------------------------------ */
    tabu.step();
    false
}

/// Keep calling [`improve_once`] until no improving neighbour exists.
pub fn improve_until_local_optimum<'g>(
    sol: &mut Solution<'g>,
    tabu: &mut DualTabu,
    global_best_density: f64,
) {
    while improve_once(sol, tabu, global_best_density) {}
}

===== src\params.rs =====
//! Parameter bundle for TSQC (Tabu Search for γ-quasi-cliques).

/// Tunables that steer tabu search, diversification and restart behaviour.
///
/// * `gamma` controls **how strong** a heavy perturbation is  
///   (fraction of the current solution to be replaced).  
/// * `gamma_target` is the **feasibility threshold** from the paper
///   (the required density γ of a quasi-clique).  
#[derive(Clone, Debug)]
pub struct Params {
    /* ─── Tabu list ─────────────────────────────────────────────── */
    pub tenure_u: usize,
    pub tenure_v: usize,

    /* ─── Diversification ───────────────────────────────────────── */
    pub gamma:        f64,   // heavy perturbation fraction
    pub heavy_prob:   f64,   // probability of choosing heavy vs. mild move

    /* ─── Quasi-clique feasibility goal ─────────────────────────── */
    pub gamma_target: f64,   // γ (target density), 0 < γ ≤ 1

    /* ─── Restart / search limits ───────────────────────────────── */
    pub stagnation_iter: usize, // diversify after this many non-improving steps
    pub max_iter:        usize, // hard cap on inner iterations
}

impl Default for Params {
    fn default() -> Self {
        Self {
            tenure_u: 7,
            tenure_v: 7,

            gamma:      0.50,
            heavy_prob: 0.40,

            /* 0.90 matches the “sparse benchmark” values in the thesis
               but can be raised (e.g. 0.999) by the caller when needed. */
            gamma_target: 0.90,

            stagnation_iter: 1_000,
            max_iter:        1_000_000,
        }
    }
}

===== src\restart.rs =====
//! Multi-start controller: constructive start → local search → diversification.

use crate::{
    construct::{greedy_k, random_k},
    diversify::{heavy_perturbation, mild_perturbation},
    neighbour::improve_until_local_optimum,
    params::Params,
    solution::Solution,
    tabu::DualTabu,
    Graph,
};
use rand::Rng;

/// Run one TSQC search for a **fixed** `k`.
///
/// Stops early once a solution reaches the desired γ-density (`p.gamma_target`).
pub fn solve_fixed_k<'g, R>(
    graph: &'g Graph,
    k: usize,
    rng: &mut R,
    p: &Params,
) -> Solution<'g>
where
    R: Rng + ?Sized,
{
    /* 1 ── deterministic greedy start */
    let mut best_sol = greedy_k(graph, k);
    let mut best_d   = best_sol.density();

    /* 2 ── local-search state */
    let mut tabu  = DualTabu::new(graph.n(), p.tenure_u, p.tenure_v);
    let mut cur   = best_sol.clone();
    let mut stagn = 0usize;

    /* 3 ── main TSQC loop */
    for iter in 0..p.max_iter {
        improve_until_local_optimum(&mut cur, &mut tabu, best_d);

        let d = cur.density();
        if d > best_d {
            best_d   = d;
            best_sol = cur.clone();
            stagn    = 0;
        } else {
            stagn += 1;
        }

        /* diversification when stuck */
        if stagn >= p.stagnation_iter {
            if rng.gen_bool(p.heavy_prob) {
                heavy_perturbation(&mut cur, &mut tabu, rng, p.gamma);
            } else {
                mild_perturbation(&mut cur, &mut tabu);
            }
            stagn = 0;
        }

        /* early exit once a γ-quasi-clique has been found */
        if best_d + f64::EPSILON >= p.gamma_target {
            break;
        }

        /* periodic random reset to escape deep local minima */
        if iter % 2_000 == 1_999 {
            cur = random_k(graph, k, rng);
            tabu.reset();
        }
    }

    best_sol
}

===== src\solution.rs =====
//! Candidate solution: a vertex subset S with cached |S| and m(S).
//!
//! • O(1) access to size and edge count.  
//! • O(n / 64) per add/remove operation.  
//! • Works together with [`Graph`] and [`DualTabu`].

use bitvec::prelude::*;
use crate::graph::Graph;

/// Mutable quasi-clique candidate bound to a single [`Graph`].
#[derive(Clone, Debug)]
pub struct Solution<'g> {
    graph:      &'g Graph,
    vertices:   BitVec,
    edge_count: usize,
    size:       usize,
}

/*───────────────────────── impl ─────────────────────────*/

impl<'g> Solution<'g> {
    /* constructors */

    /// Empty solution.
    pub fn new(graph: &'g Graph) -> Self {
        Self {
            graph,
            vertices: bitvec![0; graph.n()],
            edge_count: 0,
            size: 0,
        }
    }

    /// Build from an initial bitset; computes edge count.
    pub fn from_bitset(graph: &'g Graph, subset: &BitSlice) -> Self {
        assert_eq!(subset.len(), graph.n());

        let size = subset.count_ones();
        let mut e = 0usize;
        for i in 0..graph.n() {
            if subset[i] {
                for j in graph.neigh_row(i).iter_ones().filter(|&j| j > i) {
                    if subset[j] { e += 1; }
                }
            }
        }

        let mut vertices = BitVec::repeat(false, graph.n());
        vertices |= subset;

        Self { graph, vertices, edge_count: e, size }
    }

    /* queries */

    #[inline] pub fn size(&self) -> usize          { self.size }
    #[inline] pub fn edges(&self) -> usize         { self.edge_count }
    #[inline] pub fn bitset(&self) -> &BitVec      { &self.vertices }
    #[inline] pub fn graph(&self) -> &Graph        { self.graph }

    /// Density 2 m(S) / (|S|·(|S|−1)); returns 0 for |S| < 2.
    pub fn density(&self) -> f64 {
        if self.size < 2 { 0.0 }
        else { 2.0 * self.edge_count as f64 / (self.size * (self.size - 1)) as f64 }
    }

    pub fn is_gamma_feasible(&self, gamma: f64) -> bool {
       self.density() + f64::EPSILON >= gamma
    }
    /* mutators */

    /// Add vertex *v* (no-op if already present).
    pub fn add(&mut self, v: usize) {
        if self.vertices[v] { return; }
        let added = self.graph.neigh_row(v)
            .iter_ones()
            .filter(|&j| self.vertices[j])
            .count();
        self.vertices.set(v, true);
        self.size       += 1;
        self.edge_count += added;
    }

    /// Remove vertex *v* (no-op if absent).
    pub fn remove(&mut self, v: usize) {
        if !self.vertices[v] { return; }
        let removed = self.graph.neigh_row(v)
            .iter_ones()
            .filter(|&j| self.vertices[j])
            .count();
        self.vertices.set(v, false);
        self.size       -= 1;
        self.edge_count -= removed;
    }

    /// Toggle membership; returns `true` if *v* is in the set afterwards.
    pub fn toggle(&mut self, v: usize) -> bool {
        if self.vertices[v] { self.remove(v); false } else { self.add(v); true }
    }

    /// Clear S completely.
    pub fn clear(&mut self) {
        self.vertices.fill(false);
        self.size = 0;
        self.edge_count = 0;
    }
}

/*───────────────────────── tests ─────────────────────────*/

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Cursor;

    fn triangle_graph() -> Graph {
        let dimacs = b"p edge 3 3\ne 1 2\ne 1 3\ne 2 3\n";
        Graph::parse_dimacs(Cursor::new(dimacs)).unwrap()
    }

    #[test]
    fn add_remove_consistency() {
        let g = triangle_graph();
        let mut sol = Solution::new(&g);

        sol.add(0);
        sol.add(1);
        sol.add(2);
        approx::assert_relative_eq!(sol.density(), 1.0);

        sol.remove(1);
        assert_eq!(sol.size(), 2);
        assert_eq!(sol.edges(), 1);
    }
}

===== src\tabu.rs =====
//! Dual-tabu list with *adaptive* tenures (Section 5.3 of the TSQC PDF).
//!
//! Tenures are recalculated every time the solution size |S| changes:
//!     Tu = ⌈0.6 · |S|⌉ and Tv = ⌈0.4 · |S|⌉.

#[derive(Clone, Debug)]
pub struct DualTabu {
    expiry_u: Vec<usize>,
    expiry_v: Vec<usize>,
    iter:     usize,
    tu:       usize,
    tv:       usize,
}

impl DualTabu {
    /*────────── constructor ──────────*/

    pub fn new(n: usize, initial_tu: usize, initial_tv: usize) -> Self {
        Self {
            expiry_u: vec![0; n],
            expiry_v: vec![0; n],
            iter:     0,
            tu:       initial_tu.max(1),
            tv:       initial_tv.max(1),
        }
    }

    /*────────── adaptive tenure ──────────*/

    /// Recompute Tu and Tv for the current |S|.
    pub fn update_tenures(&mut self, size_s: usize) {
        self.tu = ((size_s as f64) * 0.6).ceil().max(1.0) as usize;
        self.tv = ((size_s as f64) * 0.4).ceil().max(1.0) as usize;
    }

    /*────────── iteration control ──────────*/

    #[inline] pub fn step(&mut self) { self.iter += 1; }

    /*────────── tabu queries ──────────*/

    #[inline] pub fn is_tabu_u(&self, v: usize) -> bool {
        self.expiry_u[v] > self.iter
    }
    #[inline] pub fn is_tabu_v(&self, v: usize) -> bool {
        self.expiry_v[v] > self.iter
    }

    /*────────── tabu setters ──────────*/

    #[inline] pub fn forbid_u(&mut self, v: usize) {
        self.expiry_u[v] = self.iter + self.tu;
    }
    #[inline] pub fn forbid_v(&mut self, v: usize) {
        self.expiry_v[v] = self.iter + self.tv;
    }

    /*────────── reset after diversification ──────────*/

    pub fn reset(&mut self) {
        self.expiry_u.fill(0);
        self.expiry_v.fill(0);
    }
}


/*──────────── unit tests ────────────*/
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn basic_tabu_logic() {
        let mut t = DualTabu::new(3, 2, 3); // Tu=2, Tv=3

        // iteration 0
        assert!(!t.is_tabu_u(1));
        t.forbid_u(1);
        t.forbid_v(2);

        // iteration 0: forbids take effect immediately
        assert!( t.is_tabu_u(1));
        assert!( t.is_tabu_v(2));

        t.step(); // iter 1
        assert!( t.is_tabu_u(1)); // still tabu (expiry 2)
        assert!( t.is_tabu_v(2)); // still tabu (expiry 3)

        t.step(); // iter 2
        assert!(!t.is_tabu_u(1)); // U-tabu expired
        assert!( t.is_tabu_v(2)); // V-tabu still active

        t.step(); // iter 3
        assert!(!t.is_tabu_v(2)); // V-tabu expired
    }
}

===== tests\smoke.rs =====
use tsqc::{Graph, Params, solve_fixed_k};
use rand_chacha::ChaCha8Rng;
use rand::SeedableRng;

#[test]
fn smoke_fixed_k() {
    // 5-vertex complete graph minus one edge (2-3 missing)
    let edges = vec![
        (0,1),(0,2),(0,3),(0,4),
        (1,2),(1,3),(1,4),
        (2,4),
        (3,4),
    ];
    let g = Graph::from_edge_list(5, &edges);

    let mut rng = ChaCha8Rng::seed_from_u64(1);
    let sol = solve_fixed_k(&g, 5, &mut rng, &Params::default());

    // Solver should reach at least the original 0.9 density,
    // and may reach 1.0 after improving the edge set.
    assert!(sol.density() >= 0.9);
}

===== tsqc\__init__.py =====
"""
Python façade for the native Rust extension.

Import order:
1.   import tsqc         → this file
2.   this file imports tsqc._native (compiled pyd/so)
3.   re-exports the three PyO3 functions at top level
"""

from importlib import import_module, metadata as _md

# load the shared library (tsqc/_native.*)
_native = import_module("tsqc._native")

# re-export selected symbols so callers can do:  from tsqc import solve_k_py
solve_k_py      = _native.solve_k_py
solve_max_py    = _native.solve_max_py
parse_dimacs_py = _native.parse_dimacs_py

__all__ = [
    "solve_k_py",
    "solve_max_py",
    "parse_dimacs_py",
]

__version__ = _md.version("tsqc")

# clean up internal names
del _native, import_module, _md

===== tsqc\benchmarks.py =====
"""
Batch-run TSQC on a folder of DIMACS graphs.

Example:
    python -m tsqc.benchmarks -d benchmarks -g 0.7,0.8,0.9 -r 3
"""

from __future__ import annotations
from pathlib import Path
from typing import List
import argparse, pandas as pd, itertools, sys

from tsqc.runner import run_instance


def parse_gamma_list(s: str) -> List[float]:
    return [float(x) for x in s.split(",") if x.strip()]


def benchmark_dimacs(
    dimacs_dir: Path,
    pattern: str,
    gammas: List[float],
    runs: int,
    k_target: int | None,
) -> pd.DataFrame:
    """
    Run TSQC over every file matching pattern × every γ.
    Keeps the best run per (file, γ).
    """
    rows = []
    files = sorted(dimacs_dir.glob(pattern))
    total = len(files) * len(gammas)
    print(f"Benchmarking {total} combos …\n")

    for file_path, gamma in itertools.product(files, gammas):
        if file_path.name.startswith("._"):  # macOS junk
            continue
        print(f"→ {file_path.name}  γ={gamma}")
        res = run_instance(file_path, gamma, runs=runs, k_target=k_target)
        rows.append(res)

    return pd.DataFrame(rows)


# ─────────────────────────── CLI ────────────────────────────
def main(argv: list[str] | None = None) -> None:
    parser = argparse.ArgumentParser("TSQC DIMACS benchmark")
    parser.add_argument("-d", "--dir",      type=Path, required=True)
    parser.add_argument("-p", "--pattern",  default="*.clq")
    parser.add_argument("-g", "--gammas",   required=True,
                        help="Comma-sep list, e.g. 0.7,0.8")
    parser.add_argument("-r", "--runs",     type=int, default=1,
                        help="Independent runs each combo")
    parser.add_argument("-k", "--k",        type=int,
                        help="Fixed size k instead of any-k search")
    parser.add_argument("-o", "--out",      type=Path,
                        default=Path("benchmark_results.csv"))
    args = parser.parse_args(argv)

    df = benchmark_dimacs(
        args.dir, args.pattern,
        parse_gamma_list(args.gammas),
        args.runs, args.k,
    )

    args.out.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(args.out, index=False)
    print(f"\n✓ Results saved -> {args.out}")


if __name__ == "__main__":  # pragma: no cover
    main(sys.argv[1:])

===== tsqc\data_loader.py =====
"""
Fast DIMACS loader that delegates parsing to Rust when the compiled
`tsqc` wheel is available.  Falls back to pure-Python parsing if the Rust
symbol isn't present (e.g. during first `cargo test` before building the
wheel).

Usage:
    from tsqc.data_loader import load_dimacs
    n, edges = load_dimacs(Path("benchmarks/hamming8-4.clq"))
"""

from pathlib import Path
from typing import List, Tuple

try:
    # when the wheel is installed, this is the ultra-fast Rust parser
    from tsqc import parse_dimacs_py   # PyO3 export
except ImportError:
    parse_dimacs_py = None


# ---------------------------------------------------------------------------
def _python_dimacs(path: Path) -> Tuple[int, List[Tuple[int, int]]]:
    """Portable fallback DIMACS parser (line-by-line, ASCII)."""
    n_vertices = 0
    edges: List[Tuple[int, int]] = []

    with path.open("r", encoding="utf8") as fh:
        for line in fh:
            line = line.strip()
            if not line or line.startswith("c"):
                continue
            if line.startswith("p"):
                # line: 'p edge <n> <m>'
                parts = line.split()
                if len(parts) >= 3:
                    n_vertices = int(parts[2])
            elif line.startswith("e"):
                # line: 'e <u> <v>'  (1-based indices)
                parts = line.split()
                if len(parts) >= 3:
                    u = int(parts[1]) - 1
                    v = int(parts[2]) - 1
                    edges.append((u, v))

    return n_vertices, edges


# ---------------------------------------------------------------------------
def load_dimacs(path: Path) -> Tuple[int, List[Tuple[int, int]]]:
    """
    Returns (n_vertices, edge_list with 0-based indices).
    Tries the Rust backend first for speed, otherwise uses Python fallback.
    """
    if parse_dimacs_py is not None:
        return parse_dimacs_py(str(path))
    return _python_dimacs(path)

===== tsqc\dump_tree.py =====
#!/usr/bin/env python
"""
Create a single-file snapshot of the project tree without duplicate paths.

Examples
--------
# dump only the real source tree
python tools/dump_tree.py -o snapshot.txt -i src

# default (whole project, but unique relative paths)
python tools/dump_tree.py
"""
from pathlib import Path
import mimetypes, argparse, textwrap, sys

# ─────────────────────────────────────────────────────────────────────────────
EXCLUDE_DIRS = {
    ".git", ".venv", "target", ".github", "dist", "build",
    "__pycache__", ".idea", ".vscode", "_old", "backup", ".history",
    ".ipynb_checkpoints", ".txt",
}
ALLOWED_EXTS = {".py", ".rs", ".toml", ".json", ".md", ".txt", ".yml", ".yaml"}
MAX_BYTES_DEFAULT  = 100_000   # skip huge generated files
MAX_LINES_DEFAULT  = 4_000
# ─────────────────────────────────────────────────────────────────────────────

def excluded(path: Path) -> bool:
    return any(part in EXCLUDE_DIRS for part in path.parts)

def looks_text(path: Path) -> bool:
    mime, _ = mimetypes.guess_type(path)
    return mime is None or mime.startswith("text/") or mime.endswith("+json")

def dump_project(out: Path, root: Path,
                 include_glob: str | None,
                 max_bytes: int, max_lines: int):
    seen: set[str] = set()
    dumped   = 0
    skipped  = 0

    with out.open("w", encoding="utf-8") as fh:
        files = sorted(root.rglob("*"))
        if include_glob:
            files = [p for p in files if p.match(include_glob)]

        for p in files:
            if p.is_dir() or excluded(p):
                continue
            if p.suffix.lower() not in ALLOWED_EXTS:
                continue
            rel = str(p.relative_to(root))
            if rel in seen:
                skipped += 1
                continue
            seen.add(rel)

            if not looks_text(p) or p.stat().st_size > max_bytes:
                continue

            fh.write(f"{'='*5} {rel} {'='*5}\n")
            try:
                lines = p.read_text(encoding="utf-8", errors="replace").splitlines()
            except Exception as e:
                fh.write(f"[skip: {e}]\n\n")
                continue

            if len(lines) > max_lines:
                lines = lines[:max_lines] + [f"... ({len(lines)-max_lines} lines truncated)"]
            fh.write("\n".join(lines) + "\n\n")
            dumped += 1

    print(f"Snapshot written to {out}  ({dumped} files, {skipped} duplicates skipped)")

# ─────────────────────────────────────────────────────────────────────────────
def main(argv: list[str] | None = None):
    ap = argparse.ArgumentParser(
        formatter_class=argparse.RawTextHelpFormatter,
        description=textwrap.dedent("""\
            Dump all text source files into a single txt while ignoring duplicates.

            Typical usage:
              python tools/dump_tree.py -i src          # only real code
              python tools/dump_tree.py -o snapshot.txt # whole repo
        """))
    ap.add_argument("-o", "--output", default="project_snapshot.txt",
                    help="Output file (default: %(default)s)")
    ap.add_argument("-i", "--include", metavar="GLOB", default=None,
                    help="Only include paths matching this glob (e.g. 'src/**')")
    ap.add_argument("-n", "--lines", type=int, default=MAX_LINES_DEFAULT,
                    help="Max lines per file (default: %(default)s)")
    ap.add_argument("-b", "--bytes", type=int, default=MAX_BYTES_DEFAULT,
                    help="Max file size in bytes (default: %(default)s)")
    args = ap.parse_args(argv)

    dump_project(Path(args.output), Path.cwd(),
                 args.include, args.bytes, args.lines)

if __name__ == "__main__":
    main(sys.argv[1:])

===== tsqc\runner.py =====
"""
Run the Rust TSQC solver on one DIMACS instance.

Modes
-----
1. Any-k search        (default)
2. Fixed k             (--k N)
"""

from __future__ import annotations
from pathlib import Path
from time import perf_counter
from typing import Any, Dict, Optional

# PyO3 exports from the compiled extension -----------------
from tsqc import solve_k_py, solve_max_py
from tsqc.data_loader import load_dimacs


def run_instance(
    path: Path,
    gamma: float,
    runs: int = 1,
    k_target: Optional[int] = None,
    seed_base: int = 42,
) -> Dict[str, Any]:
    """
    Execute TSQC *runs* times on a DIMACS file and keep the best result.

    Returns a JSON-ready dict with:
        {instance, gamma, n_vertices, n_edges,
         best_size, density, time_s}
    """
    n_vertices, edge_list = load_dimacs(path)

    best_size: int = -1
    best_density: float = 0.0
    best_time: float = float("inf")

    for i in range(runs):
        seed = seed_base + i
        start = perf_counter()

        if k_target is None:
            # ---------- any-k search ----------
            size, density = solve_max_py(edge_list, n_vertices, gamma, seed)
        else:
            # ---------- fixed-k search ----------
            density = solve_k_py(edge_list, n_vertices, k_target, gamma, seed)
            size = k_target

        elapsed = perf_counter() - start

        if density > best_density or (density == best_density and elapsed < best_time):
            best_density = density
            best_size = size
            best_time = elapsed

    return {
        "instance":   path.name,
        "gamma":      gamma,
        "n_vertices": n_vertices,
        "n_edges":    len(edge_list),
        "best_size":  best_size,
        "density":    best_density,
        "time_s":     best_time,
    }


# ─────────────────────────── CLI ────────────────────────────
if __name__ == "__main__":  # pragma: no cover
    import argparse, json

    parser = argparse.ArgumentParser("Run TSQC on one DIMACS instance")
    parser.add_argument("-i", "--instance", type=Path, required=True)
    parser.add_argument("-g", "--gamma",   type=float, required=True,
                        help="Target density threshold γ (0<γ≤1)")
    parser.add_argument("-r", "--runs",    type=int,   default=1,
                        help="Independent runs for the same parameters")
    parser.add_argument("-k", "--k",       type=int,
                        help="Fix subset size instead of any-k search")
    parser.add_argument("-s", "--seed",    type=int,   default=42,
                        help="Base RNG seed (incremented per run)")
    parser.add_argument("-o", "--out",     type=Path,
                        help="Write JSON result to file")
    args = parser.parse_args()

    res = run_instance(args.instance, args.gamma, args.runs, args.k, args.seed)

    if args.out:
        args.out.parent.mkdir(parents=True, exist_ok=True)
        args.out.write_text(json.dumps(res, indent=2))
        print(f"✓ saved → {args.out}")
    else:
        print(json.dumps(res, indent=2))

